<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Stanford-cs231N笔记：训练神经网络, ACM,C++,algorithm">
    <meta name="description" content="激活函数
Sigmoid函数$\sigma(x) &amp;#x3D; \frac{1}{1 + e^{-x}}$ 
特征
最原始的激活函数，输出在$[0,1]$。

对神经元的激活具有很好的解释性：完全未激活为0，激活为1


缺点
导致梯度消失">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Stanford-cs231N笔记：训练神经网络 | Knowledge</title>
    <link rel="icon" type="image/png" href="/my_favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 6.1.0"></head>




<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/my_logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Knowledge</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/my_logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Knowledge</div>
        <div class="logo-desc">
            
            share life
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/knowledge-llz" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/knowledge-llz" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    
<script src="/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/20.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Stanford-cs231N笔记：训练神经网络</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">
                                <span class="chip bg-color">机器学习</span>
                            </a>
                        
                            <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">
                                <span class="chip bg-color">计算机视觉</span>
                            </a>
                        
                            <a href="/tags/KNN/">
                                <span class="chip bg-color">KNN</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" class="post-category">
                                人工智能
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2022-11-20
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2022-11-20
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    5.6k
                </div>
                

                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><p><img src="/2022/11/20/cs231n-3/image-20221119235544124.png" alt="常见的激活函数"></p>
<h4 id="Sigmoid函数"><a href="#Sigmoid函数" class="headerlink" title="Sigmoid函数"></a>Sigmoid函数</h4><p>$\sigma(x) &#x3D; \frac{1}{1 + e^{-x}}$ </p>
<h5 id="特征"><a href="#特征" class="headerlink" title="特征"></a>特征</h5><ul>
<li><p>最原始的激活函数，输出在$[0,1]$。</p>
</li>
<li><p>对神经元的激活具有很好的解释性：完全未激活为0，激活为1</p>
</li>
</ul>
<h5 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h5><ul>
<li><p><strong>导致梯度消失</strong>：导数($\sigma’(x)&#x3D;\sigma(x)(1-\sigma(x))$) 最大值为0.25，当网络层数较深时，梯度在反向传播时传播不远会逐渐消失</p>
</li>
<li><p><strong>值域不是零均值的</strong>：神经网络中接受来自前一层的输入全为正时，反向传播的梯度将会全部为正或全为负，导致梯度更新路径出现”zig zag”的情况。</p>
<img src="image-20221120000613765.png" alt="image-20221120000613765" style="zoom:67%;" />
</li>
<li><p><strong>exp()的计算有点大</strong>：这个不是很大的问题，只是相比ReLU确实慢一点</p>
</li>
</ul>
<h4 id="tanh-x-函数"><a href="#tanh-x-函数" class="headerlink" title="tanh(x)函数"></a>tanh(x)函数</h4><h5 id="特征-1"><a href="#特征-1" class="headerlink" title="特征"></a>特征</h5><ul>
<li>输出值域在[-1, 1]</li>
<li>零均值化</li>
<li>仍然存在梯度消失的问题</li>
</ul>
<p>注：tanh(x)其实就是被缩放的sigmoid函数，$tanh(x) &#x3D; 2\sigma(2x)-1$</p>
<h4 id="ReLU函数"><a href="#ReLU函数" class="headerlink" title="ReLU函数"></a>ReLU函数</h4><p>$f(x)&#x3D;max(0,x)$</p>
<h5 id="特征-2"><a href="#特征-2" class="headerlink" title="特征"></a>特征</h5><ul>
<li>不存在梯度消失问题</li>
<li>非常便于计算</li>
<li>收敛速度更快</li>
<li>相比sigmoid，在生物学上更具有可解释性</li>
</ul>
<h5 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h5><ul>
<li><strong>不是零均值化的</strong></li>
<li><strong>较为脆弱</strong>：当学习率过大时，权重更新过了，成为一个小负数，神经元很容易“死亡”。比如说，如果有一个很大的梯度通过ReLU神经元，而如果你的学习率设置的也非常大，那么这就会导致你的权重被更新过头了，变成一个很小的负数。由于权重为负，那么如果输入的值为正数（一般都为正数），那么输出也为负数，经过ReLU函数后就变成了0，此时，反向传播时会发现该神经元的梯度为0，那么这个神经元的权值永远不会被更新。这种情况发生，那么该神经元的梯度将永远变为0。也就是说，在训练过程中，某些神经元可能会不可逆转地死亡。比如说，如果学习率设置过高，你会发现有大约40%的神经元死亡，当然用恰当的学习率可以使得这一情况很少发生。</li>
</ul>
<h4 id="Leaky-ReLU"><a href="#Leaky-ReLU" class="headerlink" title="Leaky ReLU"></a>Leaky ReLU</h4><p>$f(x) &#x3D; max(0.01, x)$</p>
<h5 id="特征-3"><a href="#特征-3" class="headerlink" title="特征"></a>特征</h5><ul>
<li>解决ReLU导致神经元容易死亡的一种尝试</li>
</ul>
<h4 id="Maxout"><a href="#Maxout" class="headerlink" title="Maxout"></a>Maxout</h4><p>$max(W_1^Tx+b_1,W_2^Tx+b_2)$</p>
<h5 id="特征-4"><a href="#特征-4" class="headerlink" title="特征"></a>特征</h5><ul>
<li>是ReLU和Leaky ReLU的一般化版本</li>
<li>不会饱和，不会死亡</li>
<li>训练的参数会扩大两倍</li>
</ul>
<h4 id="激活函数的选择"><a href="#激活函数的选择" class="headerlink" title="激活函数的选择"></a>激活函数的选择</h4><ul>
<li>通常使用ReLU。注意学习率的设置</li>
<li>尝试使用Leaky ReLU&#x2F;Maxout&#x2F;ELU</li>
<li>也可以尝试tanh，但不要抱太大期待</li>
<li>不要用sigmoid</li>
</ul>
<h3 id="数据处理（Preprocess-the-data）"><a href="#数据处理（Preprocess-the-data）" class="headerlink" title="数据处理（Preprocess the data）"></a>数据处理（Preprocess the data）</h3><h4 id="零均值化-（Mean-Subtraction）"><a href="#零均值化-（Mean-Subtraction）" class="headerlink" title="零均值化 （Mean Subtraction）"></a>零均值化 （Mean Subtraction）</h4><p>对于每个特征属性，减去这个属性的平均值。</p>
<p>解释一：同激活函数的解释，避免梯度更新出现”zig zag path”</p>
<p>解释二：如下图所示：对于权值的微小变化不那么敏感，易于权值的更新与优化</p>
<p><img src="/2022/11/20/cs231n-3/image-20221120092520162.png" alt="零均值和归一化的解释"></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 注意：训练集、验证集、测试集都要减去训练集的平均值</span>
mean_image <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>
X_train <span class="token operator">-=</span> mean_image
X_val <span class="token operator">-=</span> mean_image
X_test <span class="token operator">-=</span> mean_image
X_dev <span class="token operator">-=</span> mean_image<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<h4 id="归一化（Normalization）"><a href="#归一化（Normalization）" class="headerlink" title="归一化（Normalization）"></a>归一化（Normalization）</h4><p>对数据维度进行归一化，使其具有大致相同的尺度</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">X <span class="token operator">/=</span> np<span class="token punctuation">.</span>std<span class="token punctuation">(</span>X<span class="token punctuation">,</span> asix <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>注：对于图像处理而言，像素的相对尺度大致相等，一般不进行归一化处理。</p>
<h4 id="PCA和白化（PCA-and-Whitening）"><a href="#PCA和白化（PCA-and-Whitening）" class="headerlink" title="PCA和白化（PCA and Whitening）"></a>PCA和白化（PCA and Whitening）</h4><p><img src="/2022/11/20/cs231n-3/image-20221120093808176.png" alt="原始数据-PCA降维-白化后的数据"></p>
<p><a target="_blank" rel="noopener" href="https://cs231n.github.io/neural-networks-2/">PCA和白化官方笔记</a></p>
<p><strong>常见的误区：</strong>关于预处理的一个重要观点是，任何预处理的统计数据（如数据平均值）必须只在训练数据上计算，然后再应用于验证&#x2F;测试数据。例如，计算整个数据集的平均值并将整个数据集中的每个像素都减去它，然后将数据分割成训练集、验证集、测试集，这是一个错误的做法。相反，应当只计算训练集中数据的平均值，然后在使用到验证集和测试集时减去训练集的平均值。</p>
<p><em>TODO 使用后附上代码</em></p>
<h3 id="权值初始化（Weight-Initialization）"><a href="#权值初始化（Weight-Initialization）" class="headerlink" title="权值初始化（Weight Initialization）"></a>权值初始化（Weight Initialization）</h3><p>常见的写法：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">W <span class="token operator">=</span> <span class="token number">0.01</span><span class="token operator">*</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>D<span class="token punctuation">,</span>H<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>思考两个问题：</p>
<ol>
<li><p><strong>为什么要随机？不能是同一值，比如全部初始为0？</strong></p>
<p>如果将所有权重初始化为同一值，则会得到相同的输出，在反向传播过程中，每个神经元都会具有相同的梯度，即神经元没有差异，具有对称性，不能学习到更多信息。</p>
</li>
<li><p><strong>为什么要乘以一个小的系数，比如这里乘上0.01？</strong></p>
<p>如果初始权值过大，可能会导致所有神经元在某些激活函数下完全饱和，梯度趋近于0。</p>
</li>
</ol>
<h5 id="Xavier-initialization"><a href="#Xavier-initialization" class="headerlink" title="Xavier initialization:"></a>Xavier initialization:</h5><pre class="line-numbers language-python" data-language="python"><code class="language-python">W <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>fan_in<span class="token punctuation">,</span> fan_out<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>fan_in<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>根据输入的方差等于输出的方差推导得到，<a target="_blank" rel="noopener" href="https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf">Xavier intialization</a></p>
<h5 id="ReLu激活函数的权值初始化"><a href="#ReLu激活函数的权值初始化" class="headerlink" title="ReLu激活函数的权值初始化"></a>ReLu激活函数的权值初始化</h5><pre class="line-numbers language-python" data-language="python"><code class="language-python">W <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>fan_in<span class="token punctuation">,</span> fan_out<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>fan_in <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>直观的理解：对于ReLU激活函数，因为有一半神经元未被激活，所以除以2。具体见 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1502.01852">Kaiming He</a>。</p>
<h3 id="批量归一化-（Batch-Normalization）"><a href="#批量归一化-（Batch-Normalization）" class="headerlink" title="批量归一化 （Batch Normalization）"></a>批量归一化 （Batch Normalization）</h3><p><img src="/2022/11/20/cs231n-3/image-20221120100524117.png" alt="Batch Normalization"></p>
<p><strong>优点：</strong></p>
<ul>
<li>有利于梯度在网络中流动</li>
<li>允许很高的正确率</li>
<li>降低了对初始化的依赖性</li>
<li>可以视为正则化的一种形式</li>
</ul>
<p><em>TODO 使用后附上代码</em></p>
<h3 id="两层神经网络训练过程"><a href="#两层神经网络训练过程" class="headerlink" title="两层神经网络训练过程"></a>两层神经网络训练过程</h3><h4 id="全连接层的实现"><a href="#全连接层的实现" class="headerlink" title="全连接层的实现"></a>全连接层的实现</h4><h5 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h5><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">affine_forward</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Computes the forward pass for an affine (fully-connected) layer.

    The input x has shape (N, d_1, ..., d_k) and contains a minibatch of N
    examples, where each example x[i] has shape (d_1, ..., d_k). We will
    reshape each input into a vector of dimension D = d_1 * ... * d_k, and
    then transform it to an output vector of dimension M.

    Inputs:
    - x: A numpy array containing input data, of shape (N, d_1, ..., d_k)
    - w: A numpy array of weights, of shape (D, M)
    - b: A numpy array of biases, of shape (M,)

    Returns a tuple of:
    - out: output, of shape (N, M)
    - cache: (x, w, b)
    """</span>
    out <span class="token operator">=</span> <span class="token boolean">None</span>
    data_x <span class="token operator">=</span> x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    out <span class="token operator">=</span> data_x<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>w<span class="token punctuation">)</span> <span class="token operator">+</span> b
    cache <span class="token operator">=</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">)</span>
    <span class="token keyword">return</span> out<span class="token punctuation">,</span> cache<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h5 id="后向传播"><a href="#后向传播" class="headerlink" title="后向传播"></a>后向传播</h5><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">affine_backward</span><span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Computes the backward pass for an affine layer.

    Inputs:
    - dout: Upstream derivative, of shape (N, M)
    - cache: Tuple of:
      - x: Input data, of shape (N, d_1, ... d_k)
      - w: Weights, of shape (D, M)
      - b: Biases, of shape (M,)

    Returns a tuple of:
    - dx: Gradient with respect to x, of shape (N, d1, ..., d_k)
    - dw: Gradient with respect to w, of shape (D, M)
    - db: Gradient with respect to b, of shape (M,)
    """</span>
    x<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b <span class="token operator">=</span> cache
    dx<span class="token punctuation">,</span> dw<span class="token punctuation">,</span> db <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span>
    data_x <span class="token operator">=</span> x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    dx <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>dout<span class="token punctuation">,</span> w<span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">*</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    dw <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>data_x<span class="token punctuation">.</span>T<span class="token punctuation">,</span> dout<span class="token punctuation">)</span>
    db <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dout<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> dx<span class="token punctuation">,</span> dw<span class="token punctuation">,</span> db<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="ReLU层的实现"><a href="#ReLU层的实现" class="headerlink" title="ReLU层的实现"></a>ReLU层的实现</h4><h5 id="前向传播-1"><a href="#前向传播-1" class="headerlink" title="前向传播"></a>前向传播</h5><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">relu_forward</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Computes the forward pass for a layer of rectified linear units (ReLUs).

    Input:
    - x: Inputs, of any shape

    Returns a tuple of:
    - out: Output, of the same shape as x
    - cache: x
    """</span>
    out <span class="token operator">=</span> np<span class="token punctuation">.</span>maximum<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">)</span>
    cache <span class="token operator">=</span> x
    <span class="token keyword">return</span> out<span class="token punctuation">,</span> cache<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h5 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h5><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">relu_backward</span><span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Computes the backward pass for a layer of rectified linear units (ReLUs).

    Input:
    - dout: Upstream derivatives, of any shape
    - cache: Input x, of same shape as dout

    Returns:
    - dx: Gradient with respect to x
    """</span>
    dx<span class="token punctuation">,</span> x <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> cache
    dx <span class="token operator">=</span> dout
    dx<span class="token punctuation">[</span>x <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">return</span> dx<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h5 id="Inline-Question-1"><a href="#Inline-Question-1" class="headerlink" title="Inline Question 1:"></a>Inline Question 1:</h5><p>We’ve only asked you to implement ReLU, but there are a number of different activation functions that one could use in neural networks, each with its pros and cons. In particular, an issue commonly seen with activation functions is getting zero (or close to zero) gradient flow during backpropagation. Which of the following activation functions have this problem? If you consider these functions in the one dimensional case, what types of input would lead to this behaviour?</p>
<ol>
<li>Sigmoid</li>
<li>ReLU</li>
<li>Leaky ReLU</li>
</ol>
<h5 id="Answer"><a href="#Answer" class="headerlink" title="Answer:"></a>Answer:</h5><ol>
<li>Sigmoid可能会在后向传播中使梯度消失，因为$\sigma’(v) &#x3D; \sigma(v)*(1-\sigma(v))$。最大值为$\frac{1}{4}$，在后向传播过程中，随着层数的加深，梯度每次衰减$\frac{1}{4}$，传播几层后就趋近于0。</li>
<li>对于sigmoid函数如果输入的值绝对值大，则容易导致梯度消失；对于ReLU、Leaky ReLU函数如果输入的值小于0则容易导致梯度消失。</li>
</ol>
<h4 id="Loss层的实现"><a href="#Loss层的实现" class="headerlink" title="Loss层的实现"></a>Loss层的实现</h4><h5 id="softmax-loss"><a href="#softmax-loss" class="headerlink" title="softmax loss"></a>softmax loss</h5><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">softmax_loss</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Computes the loss and gradient for softmax classification.

    Inputs:
    - x: Input data, of shape (N, C) where x[i, j] is the score for the jth
      class for the ith input.
    - y: Vector of labels, of shape (N,) where y[i] is the label for x[i] and
      0 &lt;= y[i] &lt; C

    Returns a tuple of:
    - loss: Scalar giving the loss
    - dx: Gradient of the loss with respect to x
    """</span>
    loss<span class="token punctuation">,</span> dx <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span>
    
    num <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    scores <span class="token operator">=</span> x <span class="token operator">-</span> np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    scores <span class="token operator">=</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>scores<span class="token punctuation">)</span>
    sum_scores <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>scores<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    softmax <span class="token operator">=</span> scores <span class="token operator">/</span> sum_scores
    loss <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token operator">-</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>softmax<span class="token punctuation">[</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>num<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> num
    dx <span class="token operator">=</span> softmax<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
    dx<span class="token punctuation">[</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>num<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">]</span> <span class="token operator">-=</span> <span class="token number">1</span>
    dx <span class="token operator">/=</span> num
    <span class="token keyword">return</span> loss<span class="token punctuation">,</span> dx<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h5 id="svm-loss"><a href="#svm-loss" class="headerlink" title="svm loss"></a>svm loss</h5><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">svm_loss</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Computes the loss and gradient using for multiclass SVM classification.

    Inputs:
    - x: Input data, of shape (N, C) where x[i, j] is the score for the jth
      class for the ith input.
    - y: Vector of labels, of shape (N,) where y[i] is the label for x[i] and
      0 &lt;= y[i] &lt; C

    Returns a tuple of:
    - loss: Scalar giving the loss
    - dx: Gradient of the loss with respect to x
    """</span>
    loss<span class="token punctuation">,</span> dx <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span>
    
    num <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    correct_x <span class="token operator">=</span> x<span class="token punctuation">[</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>num<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span>num<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    margin <span class="token operator">=</span> x <span class="token operator">-</span> correct_x <span class="token operator">+</span> <span class="token number">1.0</span>
    margin<span class="token punctuation">[</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>num<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.0</span>
    margin <span class="token operator">=</span> np<span class="token punctuation">.</span>maximum<span class="token punctuation">(</span>margin<span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">)</span>
    loss <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>margin<span class="token punctuation">)</span> <span class="token operator">/</span> num
    dx <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    num_pos <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>margin <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    dx<span class="token punctuation">[</span>margin <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
    dx<span class="token punctuation">[</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>num<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">]</span> <span class="token operator">-=</span> num_pos
    dx <span class="token operator">=</span> dx <span class="token operator">/</span> num
    <span class="token keyword">return</span> loss<span class="token punctuation">,</span> dx<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="网络搭建"><a href="#网络搭建" class="headerlink" title="网络搭建"></a>网络搭建</h4><img src="architecture.png" alt="architecture" style="zoom:50%;" />

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> builtins <span class="token keyword">import</span> <span class="token builtin">range</span>
<span class="token keyword">from</span> builtins <span class="token keyword">import</span> <span class="token builtin">object</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">from</span> <span class="token punctuation">.</span><span class="token punctuation">.</span>layers <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> <span class="token punctuation">.</span><span class="token punctuation">.</span>layer_utils <span class="token keyword">import</span> <span class="token operator">*</span>


<span class="token keyword">class</span> <span class="token class-name">TwoLayerNet</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    A two-layer fully-connected neural network with ReLU nonlinearity and
    softmax loss that uses a modular layer design. We assume an input dimension
    of D, a hidden dimension of H, and perform classification over C classes.

    The architecure should be affine - relu - affine - softmax.

    Note that this class does not implement gradient descent; instead, it
    will interact with a separate Solver object that is responsible for running
    optimization.

    The learnable parameters of the model are stored in the dictionary
    self.params that maps parameter names to numpy arrays.
    """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        input_dim<span class="token operator">=</span><span class="token number">3</span> <span class="token operator">*</span> <span class="token number">32</span> <span class="token operator">*</span> <span class="token number">32</span><span class="token punctuation">,</span>
        hidden_dim<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>
        num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
        weight_scale<span class="token operator">=</span><span class="token number">1e-3</span><span class="token punctuation">,</span>
        reg<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Initialize a new network.

        Inputs:g the size of the hidden layer
        - num_classes: An integer givi
        - input_dim: An integer giving the size of the input
        - hidden_dim: An integer givinng the number of classes to classify
        - weight_scale: Scalar giving the standard deviation for random
          initialization of the weights.
        - reg: Scalar giving L2 regularization strength.
        """</span>
        self<span class="token punctuation">.</span>params <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
        self<span class="token punctuation">.</span>reg <span class="token operator">=</span> reg

        <span class="token comment">############################################################################</span>
        <span class="token comment"># TODO: Initialize the weights and biases of the two-layer net. Weights    #</span>
        <span class="token comment"># should be initialized from a Gaussian centered at 0.0 with               #</span>
        <span class="token comment"># standard deviation equal to weight_scale, and biases should be           #</span>
        <span class="token comment"># initialized to zero. All weights and biases should be stored in the      #</span>
        <span class="token comment"># dictionary self.params, with first layer weights                         #</span>
        <span class="token comment"># and biases using the keys 'W1' and 'b1' and second layer                 #</span>
        <span class="token comment"># weights and biases using the keys 'W2' and 'b2'.                         #</span>
        <span class="token comment">############################################################################</span>
        <span class="token comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>

        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> scale<span class="token operator">=</span>weight_scale<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>input_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> scale<span class="token operator">=</span>weight_scale<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_classes<span class="token punctuation">)</span>
        <span class="token comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>
        <span class="token comment">############################################################################</span>
        <span class="token comment">#                             END OF YOUR CODE                             #</span>
        <span class="token comment">############################################################################</span>

    <span class="token keyword">def</span> <span class="token function">loss</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Compute loss and gradient for a minibatch of data.

        Inputs:
        - X: Array of input data of shape (N, d_1, ..., d_k)
        - y: Array of labels, of shape (N,). y[i] gives the label for X[i].

        Returns:
        If y is None, then run a test-time forward pass of the model and return:
        - scores: Array of shape (N, C) giving classification scores, where
          scores[i, c] is the classification score for X[i] and class c.

        If y is not None, then run a training-time forward and backward pass and
        return a tuple of:
        - loss: Scalar value giving the loss
        - grads: Dictionary with the same keys as self.params, mapping parameter
          names to gradients of the loss with respect to those parameters.
        """</span>
        scores <span class="token operator">=</span> <span class="token boolean">None</span>
        <span class="token comment">############################################################################</span>
        <span class="token comment"># TODO: Implement the forward pass for the two-layer net, computing the    #</span>
        <span class="token comment"># class scores for X and storing them in the scores variable.              #</span>
        <span class="token comment">############################################################################</span>
        <span class="token comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>

        out1<span class="token punctuation">,</span> cache1 <span class="token operator">=</span> affine_forward<span class="token punctuation">(</span>X<span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        relu1<span class="token punctuation">,</span> cache_relu <span class="token operator">=</span> relu_forward<span class="token punctuation">(</span>out1<span class="token punctuation">)</span>
        out2<span class="token punctuation">,</span> cache2 <span class="token operator">=</span> affine_forward<span class="token punctuation">(</span>relu1<span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        scores <span class="token operator">=</span> out2

        <span class="token comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>
        <span class="token comment">############################################################################</span>
        <span class="token comment">#                             END OF YOUR CODE                             #</span>
        <span class="token comment">############################################################################</span>

        <span class="token comment"># If y is None then we are in test mode so just return scores</span>
        <span class="token keyword">if</span> y <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> scores

        loss<span class="token punctuation">,</span> grads <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
        <span class="token comment">############################################################################</span>
        <span class="token comment"># TODO: Implement the backward pass for the two-layer net. Store the loss  #</span>
        <span class="token comment"># in the loss variable and gradients in the grads dictionary. Compute data #</span>
        <span class="token comment"># loss using softmax, and make sure that grads[k] holds the gradients for  #</span>
        <span class="token comment"># self.params[k]. Don't forget to add L2 regularization!                   #</span>
        <span class="token comment">#                                                                          #</span>
        <span class="token comment"># NOTE: To ensure that your implementation matches ours and you pass the   #</span>
        <span class="token comment"># automated tests, make sure that your L2 regularization includes a factor #</span>
        <span class="token comment"># of 0.5 to simplify the expression for the gradient.                      #</span>
        <span class="token comment">############################################################################</span>
        <span class="token comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>
        loss<span class="token punctuation">,</span> dout <span class="token operator">=</span> softmax_loss<span class="token punctuation">(</span>scores<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
        loss <span class="token operator">+=</span> <span class="token number">0.5</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>reg <span class="token operator">*</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">+</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        dout<span class="token punctuation">,</span> grads<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grads<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> affine_backward<span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache2<span class="token punctuation">)</span>
        grads<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> self<span class="token punctuation">.</span>reg <span class="token operator">*</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span>
        dout <span class="token operator">=</span> relu_backward<span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache_relu<span class="token punctuation">)</span>
        dout<span class="token punctuation">,</span> grads<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grads<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> affine_backward<span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache1<span class="token punctuation">)</span>
        grads<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> self<span class="token punctuation">.</span>reg <span class="token operator">*</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span>
        <span class="token comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>
        <span class="token comment">############################################################################</span>
        <span class="token comment">#                             END OF YOUR CODE                             #</span>
        <span class="token comment">############################################################################</span>

        <span class="token keyword">return</span> loss<span class="token punctuation">,</span> grads<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="Solver类训练模型"><a href="#Solver类训练模型" class="headerlink" title="Solver类训练模型"></a>Solver类训练模型</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> __future__ <span class="token keyword">import</span> print_function<span class="token punctuation">,</span> division
<span class="token keyword">from</span> future <span class="token keyword">import</span> standard_library

standard_library<span class="token punctuation">.</span>install_aliases<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> builtins <span class="token keyword">import</span> <span class="token builtin">range</span>
<span class="token keyword">from</span> builtins <span class="token keyword">import</span> <span class="token builtin">object</span>
<span class="token keyword">import</span> os
<span class="token keyword">import</span> pickle <span class="token keyword">as</span> pickle

<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">from</span> cs231n <span class="token keyword">import</span> optim


<span class="token keyword">class</span> <span class="token class-name">Solver</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    A Solver encapsulates all the logic necessary for training classification
    models. The Solver performs stochastic gradient descent using different
    update rules defined in optim.py.

    The solver accepts both training and validataion data and labels so it can
    periodically check classification accuracy on both training and validation
    data to watch out for overfitting.

    To train a model, you will first construct a Solver instance, passing the
    model, dataset, and various options (learning rate, batch size, etc) to the
    constructor. You will then call the train() method to run the optimization
    procedure and train the model.

    After the train() method returns, model.params will contain the parameters
    that performed best on the validation set over the course of training.
    In addition, the instance variable solver.loss_history will contain a list
    of all losses encountered during training and the instance variables
    solver.train_acc_history and solver.val_acc_history will be lists of the
    accuracies of the model on the training and validation set at each epoch.

    Example usage might look something like this:

    data = &#123;
      'X_train': # training data
      'y_train': # training labels
      'X_val': # validation data
      'y_val': # validation labels
    &#125;
    model = MyAwesomeModel(hidden_size=100, reg=10)
    solver = Solver(model, data,
                    update_rule='sgd',
                    optim_config=&#123;
                      'learning_rate': 1e-4,
                    &#125;,
                    lr_decay=0.95,
                    num_epochs=5, batch_size=200,
                    print_every=100)
    solver.train()


    A Solver works on a model object that must conform to the following API:

    - model.params must be a dictionary mapping string parameter names to numpy
      arrays containing parameter values.

    - model.loss(X, y) must be a function that computes training-time loss and
      gradients, and test-time classification scores, with the following inputs
      and outputs:

      Inputs:
      - X: Array giving a minibatch of input data of shape (N, d_1, ..., d_k)
      - y: Array of labels, of shape (N,) giving labels for X where y[i] is the
        label for X[i].

      Returns:
      If y is None, run a test-time forward pass and return:
      - scores: Array of shape (N, C) giving classification scores for X where
        scores[i, c] gives the score of class c for X[i].

      If y is not None, run a training time forward and backward pass and
      return a tuple of:
      - loss: Scalar giving the loss
      - grads: Dictionary with the same keys as self.params mapping parameter
        names to gradients of the loss with respect to those parameters.
    """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model<span class="token punctuation">,</span> data<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Construct a new Solver instance.

        Required arguments:
        - model: A model object conforming to the API described above
        - data: A dictionary of training and validation data containing:
          'X_train': Array, shape (N_train, d_1, ..., d_k) of training images
          'X_val': Array, shape (N_val, d_1, ..., d_k) of validation images
          'y_train': Array, shape (N_train,) of labels for training images
          'y_val': Array, shape (N_val,) of labels for validation images

        Optional arguments:
        - update_rule: A string giving the name of an update rule in optim.py.
          Default is 'sgd'.
        - optim_config: A dictionary containing hyperparameters that will be
          passed to the chosen update rule. Each update rule requires different
          hyperparameters (see optim.py) but all update rules require a
          'learning_rate' parameter so that should always be present.
        - lr_decay: A scalar for learning rate decay; after each epoch the
          learning rate is multiplied by this value.
        - batch_size: Size of minibatches used to compute loss and gradient
          during training.
        - num_epochs: The number of epochs to run for during training.
        - print_every: Integer; training losses will be printed every
          print_every iterations.
        - verbose: Boolean; if set to false then no output will be printed
          during training.
        - num_train_samples: Number of training samples used to check training
          accuracy; default is 1000; set to None to use entire training set.
        - num_val_samples: Number of validation samples to use to check val
          accuracy; default is None, which uses the entire validation set.
        - checkpoint_name: If not None, then save model checkpoints here every
          epoch.
        """</span>
        self<span class="token punctuation">.</span>model <span class="token operator">=</span> model
        self<span class="token punctuation">.</span>X_train <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">"X_train"</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>y_train <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">"y_train"</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>X_val <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">"X_val"</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>y_val <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">"y_val"</span><span class="token punctuation">]</span>

        <span class="token comment"># Unpack keyword arguments</span>
        self<span class="token punctuation">.</span>update_rule <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"update_rule"</span><span class="token punctuation">,</span> <span class="token string">"sgd"</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>optim_config <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"optim_config"</span><span class="token punctuation">,</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>lr_decay <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"lr_decay"</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"batch_size"</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>num_epochs <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"num_epochs"</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>num_train_samples <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"num_train_samples"</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>num_val_samples <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"num_val_samples"</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>checkpoint_name <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"checkpoint_name"</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>print_every <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"print_every"</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>verbose <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"verbose"</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>

        <span class="token comment"># Throw an error if there are extra keyword arguments</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>kwargs<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>
            extra <span class="token operator">=</span> <span class="token string">", "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'"%s"'</span> <span class="token operator">%</span> k <span class="token keyword">for</span> k <span class="token keyword">in</span> <span class="token builtin">list</span><span class="token punctuation">(</span>kwargs<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"Unrecognized arguments %s"</span> <span class="token operator">%</span> extra<span class="token punctuation">)</span>

        <span class="token comment"># Make sure the update rule exists, then replace the string</span>
        <span class="token comment"># name with the actual function</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">hasattr</span><span class="token punctuation">(</span>optim<span class="token punctuation">,</span> self<span class="token punctuation">.</span>update_rule<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Invalid update_rule "%s"'</span> <span class="token operator">%</span> self<span class="token punctuation">.</span>update_rule<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>update_rule <span class="token operator">=</span> <span class="token builtin">getattr</span><span class="token punctuation">(</span>optim<span class="token punctuation">,</span> self<span class="token punctuation">.</span>update_rule<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>_reset<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_reset</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Set up some book-keeping variables for optimization. Don't call this
        manually.
        """</span>
        <span class="token comment"># Set up some variables for book-keeping</span>
        self<span class="token punctuation">.</span>epoch <span class="token operator">=</span> <span class="token number">0</span>
        self<span class="token punctuation">.</span>best_val_acc <span class="token operator">=</span> <span class="token number">0</span>
        self<span class="token punctuation">.</span>best_params <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
        self<span class="token punctuation">.</span>loss_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>train_acc_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>val_acc_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

        <span class="token comment"># Make a deep copy of the optim_config for each parameter</span>
        self<span class="token punctuation">.</span>optim_configs <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
        <span class="token keyword">for</span> p <span class="token keyword">in</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>params<span class="token punctuation">:</span>
            d <span class="token operator">=</span> <span class="token punctuation">&#123;</span>k<span class="token punctuation">:</span> v <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> self<span class="token punctuation">.</span>optim_config<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span>
            self<span class="token punctuation">.</span>optim_configs<span class="token punctuation">[</span>p<span class="token punctuation">]</span> <span class="token operator">=</span> d

    <span class="token keyword">def</span> <span class="token function">_step</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Make a single gradient update. This is called by train() and should not
        be called manually.
        """</span>
        <span class="token comment"># Make a minibatch of training data</span>
        num_train <span class="token operator">=</span> self<span class="token punctuation">.</span>X_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        batch_mask <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>num_train<span class="token punctuation">,</span> self<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>
        X_batch <span class="token operator">=</span> self<span class="token punctuation">.</span>X_train<span class="token punctuation">[</span>batch_mask<span class="token punctuation">]</span>
        y_batch <span class="token operator">=</span> self<span class="token punctuation">.</span>y_train<span class="token punctuation">[</span>batch_mask<span class="token punctuation">]</span>

        <span class="token comment"># Compute loss and gradient</span>
        loss<span class="token punctuation">,</span> grads <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>X_batch<span class="token punctuation">,</span> y_batch<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>loss_history<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

        <span class="token comment"># Perform a parameter update</span>
        <span class="token keyword">for</span> p<span class="token punctuation">,</span> w <span class="token keyword">in</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>params<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            dw <span class="token operator">=</span> grads<span class="token punctuation">[</span>p<span class="token punctuation">]</span>
            config <span class="token operator">=</span> self<span class="token punctuation">.</span>optim_configs<span class="token punctuation">[</span>p<span class="token punctuation">]</span>
            next_w<span class="token punctuation">,</span> next_config <span class="token operator">=</span> self<span class="token punctuation">.</span>update_rule<span class="token punctuation">(</span>w<span class="token punctuation">,</span> dw<span class="token punctuation">,</span> config<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>params<span class="token punctuation">[</span>p<span class="token punctuation">]</span> <span class="token operator">=</span> next_w
            self<span class="token punctuation">.</span>optim_configs<span class="token punctuation">[</span>p<span class="token punctuation">]</span> <span class="token operator">=</span> next_config

    <span class="token keyword">def</span> <span class="token function">_save_checkpoint</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>checkpoint_name <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span>
        checkpoint <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
            <span class="token string">"model"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>model<span class="token punctuation">,</span>
            <span class="token string">"update_rule"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>update_rule<span class="token punctuation">,</span>
            <span class="token string">"lr_decay"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>lr_decay<span class="token punctuation">,</span>
            <span class="token string">"optim_config"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>optim_config<span class="token punctuation">,</span>
            <span class="token string">"batch_size"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span>
            <span class="token string">"num_train_samples"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>num_train_samples<span class="token punctuation">,</span>
            <span class="token string">"num_val_samples"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>num_val_samples<span class="token punctuation">,</span>
            <span class="token string">"epoch"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>epoch<span class="token punctuation">,</span>
            <span class="token string">"loss_history"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>loss_history<span class="token punctuation">,</span>
            <span class="token string">"train_acc_history"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>train_acc_history<span class="token punctuation">,</span>
            <span class="token string">"val_acc_history"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>val_acc_history<span class="token punctuation">,</span>
        <span class="token punctuation">&#125;</span>
        filename <span class="token operator">=</span> <span class="token string">"%s_epoch_%d.pkl"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>checkpoint_name<span class="token punctuation">,</span> self<span class="token punctuation">.</span>epoch<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Saving checkpoint to "%s"'</span> <span class="token operator">%</span> filename<span class="token punctuation">)</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> <span class="token string">"wb"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            pickle<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>checkpoint<span class="token punctuation">,</span> f<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">check_accuracy</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> num_samples<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Check accuracy of the model on the provided data.

        Inputs:
        - X: Array of data, of shape (N, d_1, ..., d_k)
        - y: Array of labels, of shape (N,)
        - num_samples: If not None, subsample the data and only test the model
          on num_samples datapoints.
        - batch_size: Split X and y into batches of this size to avoid using
          too much memory.

        Returns:
        - acc: Scalar giving the fraction of instances that were correctly
          classified by the model.
        """</span>

        <span class="token comment"># Maybe subsample the data</span>
        N <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        <span class="token keyword">if</span> num_samples <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> N <span class="token operator">></span> num_samples<span class="token punctuation">:</span>
            mask <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>N<span class="token punctuation">,</span> num_samples<span class="token punctuation">)</span>
            N <span class="token operator">=</span> num_samples
            X <span class="token operator">=</span> X<span class="token punctuation">[</span>mask<span class="token punctuation">]</span>
            y <span class="token operator">=</span> y<span class="token punctuation">[</span>mask<span class="token punctuation">]</span>

        <span class="token comment"># Compute predictions in batches</span>
        num_batches <span class="token operator">=</span> N <span class="token operator">//</span> batch_size
        <span class="token keyword">if</span> N <span class="token operator">%</span> batch_size <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>
            num_batches <span class="token operator">+=</span> <span class="token number">1</span>
        y_pred <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_batches<span class="token punctuation">)</span><span class="token punctuation">:</span>
            start <span class="token operator">=</span> i <span class="token operator">*</span> batch_size
            end <span class="token operator">=</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> batch_size
            scores <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>X<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span><span class="token punctuation">)</span>
            y_pred<span class="token punctuation">.</span>append<span class="token punctuation">(</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>scores<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        y_pred <span class="token operator">=</span> np<span class="token punctuation">.</span>hstack<span class="token punctuation">(</span>y_pred<span class="token punctuation">)</span>
        acc <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>y_pred <span class="token operator">==</span> y<span class="token punctuation">)</span>

        <span class="token keyword">return</span> acc

    <span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Run optimization to train the model.
        """</span>
        num_train <span class="token operator">=</span> self<span class="token punctuation">.</span>X_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        iterations_per_epoch <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>num_train <span class="token operator">//</span> self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        num_iterations <span class="token operator">=</span> self<span class="token punctuation">.</span>num_epochs <span class="token operator">*</span> iterations_per_epoch

        <span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_iterations<span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>_step<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># Maybe print training loss</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose <span class="token keyword">and</span> t <span class="token operator">%</span> self<span class="token punctuation">.</span>print_every <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span>
                    <span class="token string">"(Iteration %d / %d) loss: %f"</span>
                    <span class="token operator">%</span> <span class="token punctuation">(</span>t <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> num_iterations<span class="token punctuation">,</span> self<span class="token punctuation">.</span>loss_history<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
                <span class="token punctuation">)</span>

            <span class="token comment"># At the end of every epoch, increment the epoch counter and decay</span>
            <span class="token comment"># the learning rate.</span>
            epoch_end <span class="token operator">=</span> <span class="token punctuation">(</span>t <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> iterations_per_epoch <span class="token operator">==</span> <span class="token number">0</span>
            <span class="token keyword">if</span> epoch_end<span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>epoch <span class="token operator">+=</span> <span class="token number">1</span>
                <span class="token keyword">for</span> k <span class="token keyword">in</span> self<span class="token punctuation">.</span>optim_configs<span class="token punctuation">:</span>
                    self<span class="token punctuation">.</span>optim_configs<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"learning_rate"</span><span class="token punctuation">]</span> <span class="token operator">*=</span> self<span class="token punctuation">.</span>lr_decay

            <span class="token comment"># Check train and val accuracy on the first iteration, the last</span>
            <span class="token comment"># iteration, and at the end of each epoch.</span>
            first_it <span class="token operator">=</span> t <span class="token operator">==</span> <span class="token number">0</span>
            last_it <span class="token operator">=</span> t <span class="token operator">==</span> num_iterations <span class="token operator">-</span> <span class="token number">1</span>
            <span class="token keyword">if</span> first_it <span class="token keyword">or</span> last_it <span class="token keyword">or</span> epoch_end<span class="token punctuation">:</span>
                train_acc <span class="token operator">=</span> self<span class="token punctuation">.</span>check_accuracy<span class="token punctuation">(</span>
                    self<span class="token punctuation">.</span>X_train<span class="token punctuation">,</span> self<span class="token punctuation">.</span>y_train<span class="token punctuation">,</span> num_samples<span class="token operator">=</span>self<span class="token punctuation">.</span>num_train_samples
                <span class="token punctuation">)</span>
                val_acc <span class="token operator">=</span> self<span class="token punctuation">.</span>check_accuracy<span class="token punctuation">(</span>
                    self<span class="token punctuation">.</span>X_val<span class="token punctuation">,</span> self<span class="token punctuation">.</span>y_val<span class="token punctuation">,</span> num_samples<span class="token operator">=</span>self<span class="token punctuation">.</span>num_val_samples
                <span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>train_acc_history<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_acc<span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>val_acc_history<span class="token punctuation">.</span>append<span class="token punctuation">(</span>val_acc<span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>_save_checkpoint<span class="token punctuation">(</span><span class="token punctuation">)</span>

                <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
                    <span class="token keyword">print</span><span class="token punctuation">(</span>
                        <span class="token string">"(Epoch %d / %d) train acc: %f; val_acc: %f"</span>
                        <span class="token operator">%</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>epoch<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_epochs<span class="token punctuation">,</span> train_acc<span class="token punctuation">,</span> val_acc<span class="token punctuation">)</span>
                    <span class="token punctuation">)</span>

                <span class="token comment"># Keep track of the best model</span>
                <span class="token keyword">if</span> val_acc <span class="token operator">></span> self<span class="token punctuation">.</span>best_val_acc<span class="token punctuation">:</span>
                    self<span class="token punctuation">.</span>best_val_acc <span class="token operator">=</span> val_acc
                    self<span class="token punctuation">.</span>best_params <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
                    <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>params<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                        self<span class="token punctuation">.</span>best_params<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> v<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># At the end of training swap the best params into the model</span>
        self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>params <span class="token operator">=</span> self<span class="token punctuation">.</span>best_params<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python">input_size <span class="token operator">=</span> <span class="token number">32</span> <span class="token operator">*</span> <span class="token number">32</span> <span class="token operator">*</span> <span class="token number">3</span>
hidden_size <span class="token operator">=</span> <span class="token number">50</span>
num_classes <span class="token operator">=</span> <span class="token number">10</span>
model <span class="token operator">=</span> TwoLayerNet<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>
solver <span class="token operator">=</span> <span class="token boolean">None</span>

<span class="token comment">##############################################################################</span>
<span class="token comment"># TODO: Use a Solver instance to train a TwoLayerNet that achieves about 36% #</span>
<span class="token comment"># accuracy on the validation set.                                            #</span>
<span class="token comment">##############################################################################</span>
<span class="token comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>

solver <span class="token operator">=</span> Solver<span class="token punctuation">(</span>model<span class="token punctuation">,</span>
         data<span class="token punctuation">,</span>
         optim_config<span class="token operator">=</span><span class="token punctuation">&#123;</span><span class="token string">"learning_rate"</span><span class="token punctuation">:</span><span class="token number">1e-3</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
         lr_decay<span class="token operator">=</span><span class="token number">0.95</span>
         <span class="token punctuation">)</span>
solver<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>
<span class="token comment">##############################################################################</span>
<span class="token comment">#                             END OF YOUR CODE                               #</span>
<span class="token comment">##############################################################################</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>(Iteration 1 &#x2F; 4900) loss: 2.300089 </p>
<p>(Epoch 0 &#x2F; 10) train acc: 0.171000; val_acc: 0.170000</p>
<p>(Iteration 11 &#x2F; 4900) loss: 2.258416 (Iteration 21 &#x2F; 4900) loss: 2.160948 </p>
<p>(Iteration 31 &#x2F; 4900) loss: 2.016287 (Iteration 41 &#x2F; 4900) loss: 2.138642 </p>
<p>(Iteration 51 &#x2F; 4900) loss: 2.059372 (Iteration 61 &#x2F; 4900) loss: 1.897230 </p>
<p>…</p>
<p>(Iteration 4871 &#x2F; 4900) loss: 1.216778 (Iteration 4881 &#x2F; 4900) loss: 1.309086 </p>
<p>(Iteration 4891 &#x2F; 4900) loss: 1.281954 </p>
<p>(Epoch 10 &#x2F; 10) train acc: 0.545000; val_acc: 0.483000</p>
</blockquote>
<h4 id="训练中Debug策略"><a href="#训练中Debug策略" class="headerlink" title="训练中Debug策略"></a>训练中Debug策略</h4><p>一般有两种，一是观察loss曲线，二是可视化第一层网络权重。</p>
<h5 id="可视化loss与accuracy"><a href="#可视化loss与accuracy" class="headerlink" title="可视化loss与accuracy"></a>可视化loss与accuracy</h5><p>loss函数呈现以下情况，可以粗略估计造成的原因。</p>
<p><img src="/2022/11/20/cs231n-3/image-20221120105147021.png" alt="loss-epoch"></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Training loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>solver<span class="token punctuation">.</span>loss_history<span class="token punctuation">,</span> <span class="token string">'o'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Iteration'</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Accuracy'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>solver<span class="token punctuation">.</span>train_acc_history<span class="token punctuation">,</span> <span class="token string">'-o'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>solver<span class="token punctuation">.</span>val_acc_history<span class="token punctuation">,</span> <span class="token string">'-o'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'val'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>solver<span class="token punctuation">.</span>val_acc_history<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'k--'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Epoch'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'lower right'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>gcf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>set_size_inches<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p><img src="/2022/11/20/cs231n-3/image-20221120104915010.png" alt="Training loss/acuraccy - epoch"></p>
</blockquote>
<h5 id="可视化网络第一层权值"><a href="#可视化网络第一层权值" class="headerlink" title="可视化网络第一层权值"></a>可视化网络第一层权值</h5><p>在大多数神经网络训练可视化数据时，第一层通常会展现一些可视化结构。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> cs231n<span class="token punctuation">.</span>vis_utils <span class="token keyword">import</span> visualize_grid

<span class="token comment"># Visualize the weights of the network</span>

<span class="token keyword">def</span> <span class="token function">show_net_weights</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span><span class="token punctuation">:</span>
    W1 <span class="token operator">=</span> net<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span>
    W1 <span class="token operator">=</span> W1<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>visualize_grid<span class="token punctuation">(</span>W1<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'uint8'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>gca<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

show_net_weights<span class="token punctuation">(</span>model<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p><img src="/2022/11/20/cs231n-3/image-20221120105408037.png" alt="可视化第一层网络权值"></p>
</blockquote>
<h4 id="调整超参数"><a href="#调整超参数" class="headerlink" title="调整超参数"></a>调整超参数</h4><h5 id="策略与步骤"><a href="#策略与步骤" class="headerlink" title="策略与步骤"></a>策略与步骤</h5><ol>
<li><strong>不正则化，不训练，对于随机权值计算loss值，观察此时的loss是否符合期望。</strong>如：本例中10个类别随机正确率应该为0.1，$loss &#x3D; -\log0.1&#x3D;2.3$，即对于一个随机权值的网络，最初应该得到2.3左右的loss值。</li>
<li><strong>尝试不同正则化系数，使得loss值较随机时有一定的提升。</strong>如，本例中加入不同正则化系数，使得loss值略大于2.3，到3左右挺好。</li>
<li><strong>从小数据开始训练，确保能过拟合非常小的数据，达到很高的正确率。</strong>如，可以取训练集中前20个数据进行训练，测试模型。</li>
<li><strong>learning_rate是最重要的超参数，应该优先调整。</strong>如果loss值不下降，可能是学习率过低；如果loss值变成NaN，可能学习率过高，导致向不收敛方向更新。通常设置在$[1e-3 …1e-5]$之间。</li>
<li><strong>随机超参数搜索</strong>，运行前五轮，找到不错的参数区间。</li>
<li><strong>监测训练集正确率与验证集正确率。</strong>如果gap很大，则可能是过拟合了；如果没有gap，说明还能增加模型容量。</li>
</ol>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><pre class="line-numbers language-python" data-language="python"><code class="language-python">best_model <span class="token operator">=</span> <span class="token boolean">None</span>


<span class="token comment">#################################################################################</span>
<span class="token comment"># TODO: Tune hyperparameters using the validation set. Store your best trained  #</span>
<span class="token comment"># model in best_model.                                                          #</span>
<span class="token comment">#                                                                               #</span>
<span class="token comment"># To help debug your network, it may help to use visualizations similar to the  #</span>
<span class="token comment"># ones we used above; these visualizations will have significant qualitative    #</span>
<span class="token comment"># differences from the ones we saw above for the poorly tuned network.          #</span>
<span class="token comment">#                                                                               #</span>
<span class="token comment"># Tweaking hyperparameters by hand can be fun, but you might find it useful to  #</span>
<span class="token comment"># write code to sweep through possible combinations of hyperparameters          #</span>
<span class="token comment"># automatically like we did on thexs previous exercises.                          #</span>
<span class="token comment">#################################################################################</span>
<span class="token comment"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>
best_acc <span class="token operator">=</span> <span class="token number">0</span>
hidden_dim <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">75</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span>
learning_rate <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1e-4</span><span class="token punctuation">,</span> <span class="token number">5e-4</span><span class="token punctuation">,</span> <span class="token number">1e-3</span><span class="token punctuation">,</span> <span class="token number">5e-3</span><span class="token punctuation">]</span>
regularization_strengths <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1.5</span><span class="token punctuation">]</span>
learning_rate_decay <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.95</span><span class="token punctuation">,</span> <span class="token number">0.97</span><span class="token punctuation">,</span> <span class="token number">0.99</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> hdim <span class="token keyword">in</span> hidden_dim<span class="token punctuation">:</span>
  <span class="token keyword">for</span> lr <span class="token keyword">in</span> learning_rate<span class="token punctuation">:</span>
    <span class="token keyword">for</span> reg <span class="token keyword">in</span> regularization_strengths<span class="token punctuation">:</span>
      <span class="token keyword">for</span> lrdecay <span class="token keyword">in</span> learning_rate_decay<span class="token punctuation">:</span>
        model <span class="token operator">=</span> TwoLayerNet<span class="token punctuation">(</span>hidden_dim<span class="token operator">=</span>hdim<span class="token punctuation">,</span> reg<span class="token operator">=</span>reg<span class="token punctuation">)</span>
        solver <span class="token operator">=</span> Solver<span class="token punctuation">(</span>model<span class="token punctuation">,</span>
                 data<span class="token punctuation">,</span>
                 optim_config<span class="token operator">=</span><span class="token punctuation">&#123;</span><span class="token string">'learning_rate'</span><span class="token punctuation">:</span> lr<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
                 lr_decay<span class="token operator">=</span>lrdecay<span class="token punctuation">,</span>
                 verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        solver<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'hidden_dim:&#123;0&#125;, lr:&#123;1&#125;, reg:&#123;2&#125;, lr_decay:&#123;3&#125;, accuracy:&#123;4&#125;'</span>
        <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>hdim<span class="token punctuation">,</span> lr<span class="token punctuation">,</span> reg<span class="token punctuation">,</span> lrdecay<span class="token punctuation">,</span> solver<span class="token punctuation">.</span>best_val_acc<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> solver<span class="token punctuation">.</span>best_val_acc <span class="token operator">></span> best_acc<span class="token punctuation">:</span>
          best_acc <span class="token operator">=</span> solver<span class="token punctuation">.</span>best_val_acc
          best_model <span class="token operator">=</span> model
<span class="token comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>
<span class="token comment">################################################################################</span>
<span class="token comment">#                              END OF YOUR CODE                                #</span>
<span class="token comment">################################################################################</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>hidden_dim:50, lr:0.0001, reg:0, lr_decay:0.95, accuracy:0.463<br>hidden_dim:50, lr:0.0001, reg:0, lr_decay:0.97, accuracy:0.479<br>hidden_dim:50, lr:0.0001, reg:0, lr_decay:0.99, accuracy:0.466<br>hidden_dim:50, lr:0.0001, reg:0.5, lr_decay:0.95, accuracy:0.46<br>hidden_dim:50, lr:0.0001, reg:0.5, lr_decay:0.97, accuracy:0.476<br>hidden_dim:50, lr:0.0001, reg:0.5, lr_decay:0.99, accuracy:0.457<br>hidden_dim:50, lr:0.0001, reg:1, lr_decay:0.95, accuracy:0.47<br>hidden_dim:50, lr:0.0001, reg:1, lr_decay:0.97, accuracy:0.474<br>hidden_dim:50, lr:0.0001, reg:1, lr_decay:0.99, accuracy:0.472<br>hidden_dim:50, lr:0.0001, reg:1.5, lr_decay:0.95, accuracy:0.464<br>hidden_dim:50, lr:0.0001, reg:1.5, lr_decay:0.97, accuracy:0.472<br>hidden_dim:50, lr:0.0001, reg:1.5, lr_decay:0.99, accuracy:0.458<br>hidden_dim:50, lr:0.0005, reg:0, lr_decay:0.95, accuracy:0.5<br>hidden_dim:50, lr:0.0005, reg:0, lr_decay:0.97, accuracy:0.506<br>hidden_dim:50, lr:0.0005, reg:0, lr_decay:0.99, accuracy:0.52<br>hidden_dim:50, lr:0.0005, reg:0.5, lr_decay:0.95, accuracy:0.496<br>hidden_dim:50, lr:0.0005, reg:0.5, lr_decay:0.97, accuracy:0.507</p>
</blockquote>
<h5 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h5><pre class="line-numbers language-python" data-language="python"><code class="language-python">y_test_pred <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>best_model<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">'X_test'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Test set accuracy: '</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>y_test_pred <span class="token operator">==</span> data<span class="token punctuation">[</span><span class="token string">'y_test'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<blockquote>
<p>Test set accuracy:  0.513</p>
</blockquote>
<h5 id="Inline-Question-2"><a href="#Inline-Question-2" class="headerlink" title="Inline Question 2:"></a>Inline Question 2:</h5><p>Now that you have trained a Neural Network classifier, you may find that your testing accuracy is much lower than the training accuracy. In what ways can we decrease this gap? Select all that apply.</p>
<ol>
<li>Train on a larger dataset.</li>
<li>Add more hidden units.</li>
<li>Increase the regularization strength.</li>
<li>None of the above.</li>
</ol>
<p>$\color{blue}{\textit Your Answer:}$ 1, 3</p>
<p>$\color{blue}{\textit Your Explanation:}$<br>增大数据量或者增加正则化系数，都能够提高模型的泛化能力，减少过拟合的情况</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">Knowledge</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="http://knowledge-llz.github.io/2022/11/20/cs231n-3/">http://knowledge-llz.github.io/2022/11/20/cs231n-3/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">Knowledge</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">
                                    <span class="chip bg-color">机器学习</span>
                                </a>
                            
                                <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">
                                    <span class="chip bg-color">计算机视觉</span>
                                </a>
                            
                                <a href="/tags/KNN/">
                                    <span class="chip bg-color">KNN</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2022/11/20/information-retrieval-3/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/21.jpg" class="responsive-img" alt="信息检索导论笔记（三）">
                        
                        <span class="card-title">信息检索导论笔记（三）</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2022-11-20
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Information-Retrieval/" class="post-category">
                                    Information Retrieval
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2/">
                        <span class="chip bg-color">信息检索</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2022/11/17/csp2022/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/6.jpg" class="responsive-img" alt="CSP-S 2022《数据传输》解题报告">
                        
                        <span class="card-title">CSP-S 2022《数据传输》解题报告</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2022-11-17
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            Knowledge
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/">
                        <span class="chip bg-color">动态规划</span>
                    </a>
                    
                    <a href="/tags/%E5%80%8D%E5%A2%9E/">
                        <span class="chip bg-color">倍增</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2022</span>
            
            <a href="/about" target="_blank">Knowledge</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">51.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2022";
                        var startMonth = "3";
                        var startDate = "28";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/knowledge-llz" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:925538513@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=925538513" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 925538513" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
