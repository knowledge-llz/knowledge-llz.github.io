<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Stanford-cs231N笔记（二）：线性分类器, ACM,C++,algorithm">
    <meta name="description" content="线性分类器之前学习的KNN分类器存在以下不足：

KNN分类器要存储所有训练数据，非常耗费空间

KNN分类器每次预测都需要扫描所有的训练数据，非常耗费时间


线性分类器通过构建以下两个函数：

score function：将图像映射成">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Stanford-cs231N笔记（二）：线性分类器 | Knowledge</title>
    <link rel="icon" type="image/png" href="/my_favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 6.1.0"></head>




<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/my_logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Knowledge</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/my_logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Knowledge</div>
        <div class="logo-desc">
            
            share life
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/knowledge-llz" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/knowledge-llz" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    
<script src="/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/7.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Stanford-cs231N笔记（二）：线性分类器</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">
                                <span class="chip bg-color">机器学习</span>
                            </a>
                        
                            <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">
                                <span class="chip bg-color">计算机视觉</span>
                            </a>
                        
                            <a href="/tags/%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E5%99%A8/">
                                <span class="chip bg-color">线性分类器</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" class="post-category">
                                人工智能
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2022-10-24
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2022-10-24
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    3.6k
                </div>
                

                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h3 id="线性分类器"><a href="#线性分类器" class="headerlink" title="线性分类器"></a>线性分类器</h3><p>之前学习的KNN分类器存在以下不足：</p>
<ul>
<li><p>KNN分类器要存储所有训练数据，非常耗费空间</p>
</li>
<li><p>KNN分类器每次预测都需要扫描所有的训练数据，非常耗费时间</p>
</li>
</ul>
<p>线性分类器通过构建以下两个函数：</p>
<ul>
<li>score function：将图像映射成一个分数，为每个类别打分，表示对应到每个类别可能的概率</li>
<li>loss function：反映预测标签与真实标签的差值，从而优化score function</li>
</ul>
<p>通过以上构建，将问题转化为一个最优化问题：优化score function，从而使loss function最小。</p>
<p>这个方法中只需要存储score function，而不需要存储所有训练数据，避免了KNN分类器的空间弊端；且score function采用矩阵乘法的方式，通常能够并行化处理，避免了KNN的时间弊端。</p>
<h3 id="评估函数（score-function）"><a href="#评估函数（score-function）" class="headerlink" title="评估函数（score function）"></a>评估函数（score function）</h3><h4 id="基本模型"><a href="#基本模型" class="headerlink" title="基本模型"></a>基本模型</h4><p>对于一张图片，都可以视为一个$D$维向量。假设分类器需要区分$K$种类别，定义一个score function $f:R^D\rightarrow R^K$，将$D$维空间向量映射到$K$维空间中，对于$K$维空间中每一维度的值表示这一个维度的评分。</p>
<p>在最简单的线性分类器中，定义评估函数：</p>
<p>$$f(x_i, W, b) &#x3D; Wx + b$$</p>
<p>$W[D\times K]$表示weights（权重），$x[N\times D]$表示输入N张D维图片的向量，$b[K]$表示bias（偏差），</p>
<img src="cat.png" alt="线性分类器模型示例图" style="zoom:67%;" />

<h4 id="几何理解"><a href="#几何理解" class="headerlink" title="几何理解"></a>几何理解</h4><p>运用线性分类器后，每张图片都可以看作K维空间的一个点，$W$中的每行相当于一个分类类别的K维空间超平面，如下图（将高维空间压缩至二维）所示：</p>
<img src="classifier.png" style="zoom:50%;" />

<p>改变$W$中一行其中的值，相当于对应的超平面旋转一定角度，$b$则表示对应平面平移一段距离。箭头表示分值线性上升的方向，箭头指向的一侧均为正值，另一侧均为负值。</p>
<h4 id="预测过程"><a href="#预测过程" class="headerlink" title="预测过程"></a>预测过程</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
        Use the trained weights of this linear classifier to predict labels for
        data points.

        Inputs:
        - X: A numpy array of shape (N, D) containing training data; there are N
          training samples each of dimension D.

        Returns:
        - y_pred: Predicted labels for the data in X. y_pred is a 1-dimensional
          array of length N, and each element is an integer giving the predicted
          class.
    """</span>
    y_pred <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    y <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token punctuation">,</span> self<span class="token punctuation">.</span>W<span class="token punctuation">)</span>
    y_pred <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>y<span class="token punctuation">,</span> axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>
    <span class="token keyword">return</span> y_pred<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<h3 id="损失函数（loss-function"><a href="#损失函数（loss-function" class="headerlink" title="损失函数（loss function)"></a>损失函数（loss function)</h3><p>对于上面猫猫图的预测可以发现，cat类得分最低，说明$W$矩阵是不合理的，我们需要另一个函数来量化score function的合理性，进而优化score function。这样的函数就称为损失函数，</p>
<h4 id="Multi-class-SVM-loss"><a href="#Multi-class-SVM-loss" class="headerlink" title="Multi-class SVM loss"></a>Multi-class SVM loss</h4><p>多分类支持向量机分类器的损失函数：$L_i &#x3D; \sum_{j\neq y_i} max(0, s_j-s_{y_i}+1)$</p>
<p>对应图形（也被称为铰链函数）：</p>
<img src="mul-SVM.png" alt="Mul-SVM loss" style="zoom: 67%;" />



<h4 id="softmax-loss"><a href="#softmax-loss" class="headerlink" title="softmax loss"></a>softmax loss</h4><p>softmax分类器将每个评估得分进行归一化：$\frac{e^{s_i}}{\sum_j e^{s_j}}$，从而使评分具有概率意义，表示这个类别预测的把握程度。</p>
<p>softmax分类器的损失函数：$L_i&#x3D;-\log \frac{e^{s_i}}{\sum_j e^{s_j}}$，也称为交叉熵函数。</p>
<h4 id="正则化损失"><a href="#正则化损失" class="headerlink" title="正则化损失"></a>正则化损失</h4><p>在训练中，$W$的选择并不是唯一的，可能会有多个$W$矩阵将损失函数降低到同一值，那对于多个模型我们应该如何选择呢？根据奥卡姆剃刀原理，我们希望模型越简单越好，同时也可以避免模型过拟合，提高模型的泛化能力。我们在损失函数后加上一个正则化项$R(W)$阻碍模型选择权值较大的权重。从而使损失函数变为:</p>
<p>$L&#x3D;\frac{1}{N}\sum_i L_i +\lambda R(W)$</p>
<p>前半部分表示由于预测样本导致的损失值，后半部分表示权重的损失值，其中$\lambda$是正则化系数，也属于超参数，可以通过交叉验证来选取。</p>
<h3 id="优化过程"><a href="#优化过程" class="headerlink" title="优化过程"></a>优化过程</h3><h4 id="随机梯度下降"><a href="#随机梯度下降" class="headerlink" title="随机梯度下降"></a>随机梯度下降</h4><p>有了score function与loss function，剩下的问题就是如何利用loss function 来优化score function？</p>
<p>对于一个优化问题，显然我们可以求出loss function的梯度，每次往梯度下降的方向更新权重，从而使得loss函数能够不断减小。</p>
<p>但是，当梯度下降应用在大尺度的任务中时，训练集可能有上百万个样本，因此计算损失函数同时计算出梯度并更新的操作需要针对整个训练集，这是十分浪费并且有时候是无法实现的（如果内存太小就会存不下所有样本）。一个常用的方法是将训练集随机划分为多个小批次，每次只对这一个批次的样本进行计算损失值以及梯度，然后用这个梯度进行更新参数。代码如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Vanilla Minibatch Gradient Descent</span>
 
<span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
  data_batch <span class="token operator">=</span> sample_training_data<span class="token punctuation">(</span>data<span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span> <span class="token comment"># sample 256 examples</span>
  weights_grad <span class="token operator">=</span> evaluate_gradient<span class="token punctuation">(</span>loss_fun<span class="token punctuation">,</span> data_batch<span class="token punctuation">,</span> weights<span class="token punctuation">)</span>
  weights <span class="token operator">+=</span> <span class="token operator">-</span> step_size <span class="token operator">*</span> weights_grad <span class="token comment"># perform parameter update</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="梯度计算方式"><a href="#梯度计算方式" class="headerlink" title="梯度计算方式"></a>梯度计算方式</h4><ul>
<li>数值梯度：比较慢，且是一个近似值，但是比较简单</li>
<li>解析梯度：快速精确但是由于需要推导分析，所以容易出错</li>
</ul>
<h4 id="Multiclass-SVM损失函数梯度"><a href="#Multiclass-SVM损失函数梯度" class="headerlink" title="Multiclass-SVM损失函数梯度"></a>Multiclass-SVM损失函数梯度</h4><p><img src="/2022/10/24/cs231n-2/gradient_SVM.png" alt="SVM梯度推导"></p>
<h5 id="使用循环实现："><a href="#使用循环实现：" class="headerlink" title="使用循环实现："></a><strong>使用循环实现：</strong></h5><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">svm_loss_naive</span><span class="token punctuation">(</span>W<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> reg<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Structured SVM loss function, naive implementation (with loops).

    Inputs have dimension D, there are C classes, and we operate on minibatches
    of N examples.

    Inputs:
    - W: A numpy array of shape (D, C) containing weights.
    - X: A numpy array of shape (N, D) containing a minibatch of data.
    - y: A numpy array of shape (N,) containing training labels; y[i] = c means
      that X[i] has label c, where 0 &lt;= c &lt; C.
    - reg: (float) regularization strength

    Returns a tuple of:
    - loss as single float
    - gradient with respect to weights W; an array of same shape as W
    """</span>
    dW <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>W<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>  <span class="token comment"># initialize the gradient as zero</span>
    <span class="token comment"># compute the loss and the gradient</span>
    num_classes <span class="token operator">=</span> W<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
    num_train <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    loss <span class="token operator">=</span> <span class="token number">0.0</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_train<span class="token punctuation">)</span><span class="token punctuation">:</span>
        scores <span class="token operator">=</span> X<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>dot<span class="token punctuation">(</span>W<span class="token punctuation">)</span>
        correct_class_score <span class="token operator">=</span> scores<span class="token punctuation">[</span>y<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_classes<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> j <span class="token operator">==</span> y<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">:</span>
                <span class="token keyword">continue</span>
            margin <span class="token operator">=</span> scores<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">-</span> correct_class_score <span class="token operator">+</span> <span class="token number">1</span>  <span class="token comment"># note delta = 1</span>
            <span class="token keyword">if</span> margin <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>
                loss <span class="token operator">+=</span> margin
                dW<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> j<span class="token punctuation">]</span> <span class="token operator">+=</span> X<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
                dW<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> y<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">-=</span> X<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
    <span class="token comment"># Right now the loss is a sum over all training examples, but we want it</span>
    <span class="token comment"># to be an average instead so we divide by num_train.</span>
    loss <span class="token operator">/=</span> num_train
    dW <span class="token operator">/=</span> num_train
    <span class="token comment"># Add regularization to the loss.</span>
    loss <span class="token operator">+=</span> reg <span class="token operator">*</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>W <span class="token operator">*</span> W<span class="token punctuation">)</span>
    dW <span class="token operator">+=</span> reg <span class="token operator">*</span> <span class="token number">2</span> <span class="token operator">*</span> W
    <span class="token keyword">return</span> loss<span class="token punctuation">,</span> dW
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h5 id="使用numpy向量运算实现："><a href="#使用numpy向量运算实现：" class="headerlink" title="使用numpy向量运算实现："></a><strong>使用numpy向量运算实现：</strong></h5><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">svm_loss_vectorized</span><span class="token punctuation">(</span>W<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> reg<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Structured SVM loss function, vectorized implementation.

    Inputs and outputs are the same as svm_loss_naive.
    """</span>
    loss <span class="token operator">=</span> <span class="token number">0.0</span>
    dW <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>W<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>  <span class="token comment"># initialize the gradient as zero</span>

    scores <span class="token operator">=</span> X<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>W<span class="token punctuation">)</span>
    num_train <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    correct_class_scores <span class="token operator">=</span> scores<span class="token punctuation">[</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>num_train<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">]</span>
    correct_class_scores <span class="token operator">=</span> np<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>correct_class_scores<span class="token punctuation">,</span> <span class="token punctuation">(</span>num_train<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    margin <span class="token operator">=</span> scores <span class="token operator">-</span> correct_class_scores <span class="token operator">+</span> <span class="token number">1.0</span>
    margin<span class="token punctuation">[</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>num_train<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.0</span>
    margin <span class="token operator">=</span> np<span class="token punctuation">.</span>maximum<span class="token punctuation">(</span>margin<span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">)</span>
    loss <span class="token operator">+=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>margin<span class="token punctuation">)</span> <span class="token operator">/</span> num_train
    loss <span class="token operator">+=</span> reg <span class="token operator">*</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>W <span class="token operator">*</span> W<span class="token punctuation">)</span>

    margin<span class="token punctuation">[</span>margin <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
    row_sum <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>margin<span class="token punctuation">,</span> axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
    margin<span class="token punctuation">[</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>num_train<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span>row_sum
    dW <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token punctuation">.</span>T<span class="token punctuation">,</span> margin<span class="token punctuation">)</span> <span class="token operator">/</span> num_train
    dW <span class="token operator">+=</span> <span class="token number">2</span> <span class="token operator">*</span> reg <span class="token operator">*</span> W
    <span class="token keyword">return</span> loss<span class="token punctuation">,</span> dW<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<h4 id="softmax损失函数梯度"><a href="#softmax损失函数梯度" class="headerlink" title="softmax损失函数梯度"></a>softmax损失函数梯度</h4><p><img src="/2022/10/24/cs231n-2/gradient_softmax.png" alt="softmax梯度推导"></p>
<h5 id="使用循环实现：-1"><a href="#使用循环实现：-1" class="headerlink" title="使用循环实现："></a><strong>使用循环实现：</strong></h5><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">softmax_loss_naive</span><span class="token punctuation">(</span>W<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> reg<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Softmax loss function, naive implementation (with loops)

    Inputs have dimension D, there are C classes, and we operate on minibatches
    of N examples.

    Inputs:
    - W: A numpy array of shape (D, C) containing weights.
    - X: A numpy array of shape (N, D) containing a minibatch of data.
    - y: A numpy array of shape (N,) containing training labels; y[i] = c means
      that X[i] has label c, where 0 &lt;= c &lt; C.
    - reg: (float) regularization strength

    Returns a tuple of:
    - loss as single float
    - gradient with respect to weights W; an array of same shape as W
    """</span>
    <span class="token comment"># Initialize the loss and gradient to zero.</span>
    loss <span class="token operator">=</span> <span class="token number">0.0</span>
    dW <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>W<span class="token punctuation">)</span>

    num_train <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    num_classes <span class="token operator">=</span> W<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>

    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_train<span class="token punctuation">)</span><span class="token punctuation">:</span>
      scores <span class="token operator">=</span> X<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>dot<span class="token punctuation">(</span>W<span class="token punctuation">)</span>
      scores <span class="token operator">-=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>scores<span class="token punctuation">)</span> <span class="token comment">#让数值更稳定</span>
      scores <span class="token operator">=</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>scores<span class="token punctuation">)</span>
      softmax <span class="token operator">=</span> scores <span class="token operator">/</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>scores<span class="token punctuation">)</span>
      loss <span class="token operator">+=</span> <span class="token operator">-</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>softmax<span class="token punctuation">[</span>y<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
      <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_classes<span class="token punctuation">)</span><span class="token punctuation">:</span>
        dW<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> j<span class="token punctuation">]</span> <span class="token operator">+=</span> softmax<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">*</span> X<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
      dW<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> y<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">-=</span> X<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
    loss <span class="token operator">/=</span> num_train
    loss <span class="token operator">+=</span> reg <span class="token operator">*</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>W <span class="token operator">*</span> W<span class="token punctuation">)</span>
    dW <span class="token operator">/=</span> num_train
    dW <span class="token operator">+=</span> reg <span class="token operator">*</span> <span class="token number">2</span> <span class="token operator">*</span> W
    
    <span class="token keyword">return</span> loss<span class="token punctuation">,</span> dW
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><strong>使用numpy向量运算实现：</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">softmax_loss_vectorized</span><span class="token punctuation">(</span>W<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> reg<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Softmax loss function, vectorized version.

    Inputs and outputs are the same as softmax_loss_naive.
    """</span>
    <span class="token comment"># Initialize the loss and gradient to zero.</span>
    loss <span class="token operator">=</span> <span class="token number">0.0</span>
    dW <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>W<span class="token punctuation">)</span>
    num_train <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    num_classes <span class="token operator">=</span> W<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
    
    scores <span class="token operator">=</span> X<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>W<span class="token punctuation">)</span>
    scores <span class="token operator">-=</span> np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>scores<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    scores <span class="token operator">=</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>scores<span class="token punctuation">)</span>
    softmax <span class="token operator">=</span> scores <span class="token operator">/</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>scores<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    loss <span class="token operator">+=</span> <span class="token operator">-</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>softmax<span class="token punctuation">[</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>num_train<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    loss <span class="token operator">/=</span> num_train
    loss <span class="token operator">+=</span> reg <span class="token operator">*</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>W <span class="token operator">*</span> W<span class="token punctuation">)</span>
    softmax<span class="token punctuation">[</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>num_train<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">]</span> <span class="token operator">-=</span> <span class="token number">1.0</span>
    dW <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token punctuation">.</span>T<span class="token punctuation">,</span> softmax<span class="token punctuation">)</span>
    dW <span class="token operator">/=</span> num_train
    dW <span class="token operator">+=</span> reg <span class="token operator">*</span> <span class="token number">2</span> <span class="token operator">*</span> W

    <span class="token keyword">return</span> loss<span class="token punctuation">,</span> dW<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="线性分类器训练过程"><a href="#线性分类器训练过程" class="headerlink" title="线性分类器训练过程"></a>线性分类器训练过程</h3><h4 id="训练函数"><a href="#训练函数" class="headerlink" title="训练函数"></a>训练函数</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>
      self<span class="token punctuation">,</span>
      X<span class="token punctuation">,</span>
      y<span class="token punctuation">,</span>
      learning_rate<span class="token operator">=</span><span class="token number">1e-3</span><span class="token punctuation">,</span>
      reg<span class="token operator">=</span><span class="token number">1e-5</span><span class="token punctuation">,</span>
      num_iters<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>
      batch_size<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span>
      verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
  <span class="token punctuation">)</span><span class="token punctuation">:</span>
      <span class="token triple-quoted-string string">"""
      Train this linear classifier using stochastic gradient descent.

      Inputs:
      - X: A numpy array of shape (N, D) containing training data; there are N
        training samples each of dimension D.
      - y: A numpy array of shape (N,) containing training labels; y[i] = c
        means that X[i] has label 0 &lt;= c &lt; C for C classes.
      - learning_rate: (float) learning rate for optimization.
      - reg: (float) regularization strength.
      - num_iters: (integer) number of steps to take when optimizing
      - batch_size: (integer) number of training examples to use at each step.
      - verbose: (boolean) If true, print progress during optimization.

      Outputs:
      A list containing the value of the loss function at each training iteration.
      """</span>
      num_train<span class="token punctuation">,</span> dim <span class="token operator">=</span> X<span class="token punctuation">.</span>shape
      num_classes <span class="token operator">=</span> <span class="token punctuation">(</span>
          np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>
      <span class="token punctuation">)</span>  <span class="token comment"># assume y takes values 0...K-1 where K is number of classes</span>
      <span class="token keyword">if</span> self<span class="token punctuation">.</span>W <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
          <span class="token comment"># lazily initialize W</span>
          self<span class="token punctuation">.</span>W <span class="token operator">=</span> <span class="token number">0.001</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>

      <span class="token comment"># Run stochastic gradient descent to optimize W</span>
      loss_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
      <span class="token keyword">for</span> it <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_iters<span class="token punctuation">)</span><span class="token punctuation">:</span>
          X_batch <span class="token operator">=</span> <span class="token boolean">None</span>
          y_batch <span class="token operator">=</span> <span class="token boolean">None</span>

          idx <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>num_train<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> replace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
          X_batch <span class="token operator">=</span> X<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>
          y_batch <span class="token operator">=</span> y<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>

          <span class="token comment"># evaluate loss and gradient</span>
          loss<span class="token punctuation">,</span> grad <span class="token operator">=</span> self<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>X_batch<span class="token punctuation">,</span> y_batch<span class="token punctuation">,</span> reg<span class="token punctuation">)</span>
          loss_history<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

          <span class="token comment"># perform parameter update</span>

          self<span class="token punctuation">.</span>W <span class="token operator">-=</span> grad <span class="token operator">*</span> learning_rate

          <span class="token keyword">if</span> verbose <span class="token keyword">and</span> it <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
              <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"iteration %d / %d: loss %f"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>it<span class="token punctuation">,</span> num_iters<span class="token punctuation">,</span> loss<span class="token punctuation">)</span><span class="token punctuation">)</span>

      <span class="token keyword">return</span> loss_history<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="梯度检测"><a href="#梯度检测" class="headerlink" title="梯度检测"></a>梯度检测</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Once you've implemented the gradient, recompute it with the code below</span>
<span class="token comment"># and gradient check it with the function we provided for you</span>

<span class="token comment"># Compute the loss and its gradient at W.</span>
loss<span class="token punctuation">,</span> grad <span class="token operator">=</span> svm_loss_naive<span class="token punctuation">(</span>W<span class="token punctuation">,</span> X_dev<span class="token punctuation">,</span> y_dev<span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">)</span>

<span class="token comment"># Numerically compute the gradient along several randomly chosen dimensions, and</span>
<span class="token comment"># compare them with your analytically computed gradient. The numbers should match</span>
<span class="token comment"># almost exactly along all dimensions.</span>
<span class="token keyword">from</span> cs231n<span class="token punctuation">.</span>gradient_check <span class="token keyword">import</span> grad_check_sparse
f <span class="token operator">=</span> <span class="token keyword">lambda</span> w<span class="token punctuation">:</span> svm_loss_naive<span class="token punctuation">(</span>w<span class="token punctuation">,</span> X_dev<span class="token punctuation">,</span> y_dev<span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
grad_numerical <span class="token operator">=</span> grad_check_sparse<span class="token punctuation">(</span>f<span class="token punctuation">,</span> W<span class="token punctuation">,</span> grad<span class="token punctuation">)</span>

<span class="token comment"># do the gradient check once again with regularization turned on</span>
<span class="token comment"># you didn't forget the regularization gradient did you?</span>
loss<span class="token punctuation">,</span> grad <span class="token operator">=</span> svm_loss_naive<span class="token punctuation">(</span>W<span class="token punctuation">,</span> X_dev<span class="token punctuation">,</span> y_dev<span class="token punctuation">,</span> <span class="token number">5e1</span><span class="token punctuation">)</span>
f <span class="token operator">=</span> <span class="token keyword">lambda</span> w<span class="token punctuation">:</span> svm_loss_naive<span class="token punctuation">(</span>w<span class="token punctuation">,</span> X_dev<span class="token punctuation">,</span> y_dev<span class="token punctuation">,</span> <span class="token number">5e1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
grad_numerical <span class="token operator">=</span> grad_check_sparse<span class="token punctuation">(</span>f<span class="token punctuation">,</span> W<span class="token punctuation">,</span> grad<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>numerical: 0.630370 analytic: 0.630370, relative error: 8.891190e-10</p>
<p>numerical: -9.484052 analytic: -9.484052, relative error: 9.805496e-12 </p>
<p>numerical: -54.907995 analytic: -54.907995, relative error: 4.217344e-12</p>
</blockquote>
<p><strong>Inline Question 1</strong></p>
<p>It is possible that once in a while a dimension in the gradcheck will not match exactly. What could such a discrepancy be caused by? Is it a reason for concern? What is a simple example in one dimension where a gradient check could fail? How would change the margin affect of the frequency of this happening? <em>Hint: the SVM loss function is not strictly speaking differentiable</em></p>
<p>$\color{blue}{\textit Your Answer:}$ </p>
<ol>
<li>可能会在某一维度不匹配</li>
<li>hinge函数在x&#x3D;1的点是不可导的。</li>
<li>例如，$f(x) &#x3D; max(0, x)$在$x &#x3D; \frac{h}{10}$处用算术法$f(x) &#x3D; \frac{f(x + h) - f(x - h)}{2h}|_{x&#x3D;\frac{h}{10}}&#x3D;\frac{11}{21}$,用解析法计算出来$f’(x)&#x3D;1$。即，在趋近于0的点会产生误差。</li>
<li>合理地选择margin计算中的$\Delta$值，避开出现在0附近</li>
</ol>
<h4 id="可视化训练效果"><a href="#可视化训练效果" class="headerlink" title="可视化训练效果"></a>可视化训练效果</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> cs231n<span class="token punctuation">.</span>classifiers <span class="token keyword">import</span> LinearSVM
svm <span class="token operator">=</span> LinearSVM<span class="token punctuation">(</span><span class="token punctuation">)</span>
tic <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
loss_hist <span class="token operator">=</span> svm<span class="token punctuation">.</span>train<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> learning_rate<span class="token operator">=</span><span class="token number">1e-7</span><span class="token punctuation">,</span> reg<span class="token operator">=</span><span class="token number">2.5e4</span><span class="token punctuation">,</span>
                      num_iters<span class="token operator">=</span><span class="token number">1500</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
toc <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'That took %fs'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>toc <span class="token operator">-</span> tic<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># A useful debugging strategy is to plot the loss as a function of</span>
<span class="token comment"># iteration number:</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>loss_hist<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Iteration number'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Loss value'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p><img src="/2022/10/24/cs231n-2/loss-iter.png" alt="损失函数关于迭代次数曲线"></p>
</blockquote>
<h4 id="超参数的选取"><a href="#超参数的选取" class="headerlink" title="超参数的选取"></a>超参数的选取</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Use the validation set to tune hyperparameters (regularization strength and</span>
<span class="token comment"># learning rate). You should experiment with different ranges for the learning</span>
<span class="token comment"># rates and regularization strengths; if you are careful you should be able to</span>
<span class="token comment"># get a classification accuracy of about 0.39 (> 0.385) on the validation set.</span>

<span class="token comment"># Note: you may see runtime/overflow warnings during hyper-parameter search. </span>
<span class="token comment"># This may be caused by extreme values, and is not a bug.</span>

<span class="token comment"># results is dictionary mapping tuples of the form</span>
<span class="token comment"># (learning_rate, regularization_strength) to tuples of the form</span>
<span class="token comment"># (training_accuracy, validation_accuracy). The accuracy is simply the fraction</span>
<span class="token comment"># of data points that are correctly classified.</span>
results <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
best_val <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span>   <span class="token comment"># The highest validation accuracy that we have seen so far.</span>
best_svm <span class="token operator">=</span> <span class="token boolean">None</span> <span class="token comment"># The LinearSVM object that achieved the highest validation rate.</span>


<span class="token comment"># Provided as a reference. You may or may not want to change these hyperparameters</span>
learning_rates <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">4e-6</span><span class="token punctuation">,</span> <span class="token number">4e-7</span><span class="token punctuation">,</span> <span class="token number">3e-7</span><span class="token punctuation">,</span> <span class="token number">2e-7</span><span class="token punctuation">,</span> <span class="token number">1e-7</span><span class="token punctuation">,</span> <span class="token number">1e-8</span><span class="token punctuation">]</span>
regularization_strengths <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">666</span><span class="token punctuation">,</span> <span class="token number">6666</span><span class="token punctuation">,</span> <span class="token number">66666</span><span class="token punctuation">,</span> <span class="token number">1e4</span><span class="token punctuation">,</span> <span class="token number">1e5</span><span class="token punctuation">]</span>

<span class="token keyword">for</span> lr <span class="token keyword">in</span> learning_rates<span class="token punctuation">:</span>
  <span class="token keyword">for</span> rs <span class="token keyword">in</span> regularization_strengths<span class="token punctuation">:</span>
    svm <span class="token operator">=</span> LinearSVM<span class="token punctuation">(</span><span class="token punctuation">)</span>
    svm<span class="token punctuation">.</span>train<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> learning_rate<span class="token operator">=</span>lr<span class="token punctuation">,</span> reg<span class="token operator">=</span>rs<span class="token punctuation">,</span>
                 num_iters<span class="token operator">=</span><span class="token number">1500</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    y_train_pred <span class="token operator">=</span> svm<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span>
    train_accuracy <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>y_train <span class="token operator">==</span> y_train_pred<span class="token punctuation">)</span>
    y_val_pred <span class="token operator">=</span> svm<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_val<span class="token punctuation">)</span>
    val_accuracy <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>y_val <span class="token operator">==</span> y_val_pred<span class="token punctuation">)</span>
    results<span class="token punctuation">[</span><span class="token punctuation">(</span>lr<span class="token punctuation">,</span> rs<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>train_accuracy<span class="token punctuation">,</span> val_accuracy<span class="token punctuation">)</span>
    <span class="token keyword">if</span> val_accuracy <span class="token operator">></span> best_val<span class="token punctuation">:</span>
      best_val <span class="token operator">=</span> val_accuracy
      best_svm <span class="token operator">=</span> svm
    
<span class="token comment"># Print out results.</span>
<span class="token keyword">for</span> lr<span class="token punctuation">,</span> reg <span class="token keyword">in</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>results<span class="token punctuation">)</span><span class="token punctuation">:</span>
    train_accuracy<span class="token punctuation">,</span> val_accuracy <span class="token operator">=</span> results<span class="token punctuation">[</span><span class="token punctuation">(</span>lr<span class="token punctuation">,</span> reg<span class="token punctuation">)</span><span class="token punctuation">]</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'lr %e reg %e train accuracy: %f val accuracy: %f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>
                lr<span class="token punctuation">,</span> reg<span class="token punctuation">,</span> train_accuracy<span class="token punctuation">,</span> val_accuracy<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'best validation accuracy achieved during cross-validation: %f'</span> <span class="token operator">%</span> best_val<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>lr 1.000000e-08 reg 6.660000e+02 train accuracy: 0.218551 val accuracy: 0.220000<br>lr 1.000000e-08 reg 6.666000e+03 train accuracy: 0.227776 val accuracy: 0.224000<br>lr 1.000000e-08 reg 1.000000e+04 train accuracy: 0.232857 val accuracy: 0.241000<br>lr 1.000000e-08 reg 6.666600e+04 train accuracy: 0.321204 val accuracy: 0.333000</p>
<p>…</p>
<p>lr 4.000000e-06 reg 1.000000e+04 train accuracy: 0.219449 val accuracy: 0.224000<br>lr 4.000000e-06 reg 6.666600e+04 train accuracy: 0.197163 val accuracy: 0.229000<br>lr 4.000000e-06 reg 1.000000e+05 train accuracy: 0.152429 val accuracy: 0.155000<br>best validation accuracy achieved during cross-validation: 0.388000</p>
</blockquote>
<h4 id="可视化交叉验证的结果"><a href="#可视化交叉验证的结果" class="headerlink" title="可视化交叉验证的结果"></a>可视化交叉验证的结果</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Visualize the cross-validation results</span>
<span class="token keyword">import</span> math
<span class="token keyword">import</span> pdb

<span class="token comment"># pdb.set_trace()</span>

x_scatter <span class="token operator">=</span> <span class="token punctuation">[</span>math<span class="token punctuation">.</span>log10<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> results<span class="token punctuation">]</span>
y_scatter <span class="token operator">=</span> <span class="token punctuation">[</span>math<span class="token punctuation">.</span>log10<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> results<span class="token punctuation">]</span>

<span class="token comment"># plot training accuracy</span>
marker_size <span class="token operator">=</span> <span class="token number">100</span>
colors <span class="token operator">=</span> <span class="token punctuation">[</span>results<span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> results<span class="token punctuation">]</span>
plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span>pad<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x_scatter<span class="token punctuation">,</span> y_scatter<span class="token punctuation">,</span> marker_size<span class="token punctuation">,</span> c<span class="token operator">=</span>colors<span class="token punctuation">,</span> cmap<span class="token operator">=</span>plt<span class="token punctuation">.</span>cm<span class="token punctuation">.</span>coolwarm<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>colorbar<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'log learning rate'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'log regularization strength'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'CIFAR-10 training accuracy'</span><span class="token punctuation">)</span>

<span class="token comment"># plot validation accuracy</span>
colors <span class="token operator">=</span> <span class="token punctuation">[</span>results<span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> results<span class="token punctuation">]</span> <span class="token comment"># default size of markers is 20</span>
plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x_scatter<span class="token punctuation">,</span> y_scatter<span class="token punctuation">,</span> marker_size<span class="token punctuation">,</span> c<span class="token operator">=</span>colors<span class="token punctuation">,</span> cmap<span class="token operator">=</span>plt<span class="token punctuation">.</span>cm<span class="token punctuation">.</span>coolwarm<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>colorbar<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'log learning rate'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'log regularization strength'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'CIFAR-10 validation accuracy'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p><img src="/2022/10/24/cs231n-2/hyper.png"></p>
</blockquote>
<h4 id="在测试集上运行"><a href="#在测试集上运行" class="headerlink" title="在测试集上运行"></a>在测试集上运行</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Evaluate the best svm on test set</span>
y_test_pred <span class="token operator">=</span> best_svm<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>
test_accuracy <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>y_test <span class="token operator">==</span> y_test_pred<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'linear SVM on raw pixels final test set accuracy: %f'</span> <span class="token operator">%</span> test_accuracy<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>linear SVM on raw pixels final test set accuracy: 0.379000</p>
</blockquote>
<h4 id="可视化W每一列的值"><a href="#可视化W每一列的值" class="headerlink" title="可视化W每一列的值"></a>可视化W每一列的值</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Visualize the learned weights for each class.</span>
<span class="token comment"># Depending on your choice of learning rate and regularization strength, these may</span>
<span class="token comment"># or may not be nice to look at.</span>
w <span class="token operator">=</span> best_svm<span class="token punctuation">.</span>W<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token comment"># strip out the bias</span>
w <span class="token operator">=</span> w<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>
w_min<span class="token punctuation">,</span> w_max <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span>
classes <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'plane'</span><span class="token punctuation">,</span> <span class="token string">'car'</span><span class="token punctuation">,</span> <span class="token string">'bird'</span><span class="token punctuation">,</span> <span class="token string">'cat'</span><span class="token punctuation">,</span> <span class="token string">'deer'</span><span class="token punctuation">,</span> <span class="token string">'dog'</span><span class="token punctuation">,</span> <span class="token string">'frog'</span><span class="token punctuation">,</span> <span class="token string">'horse'</span><span class="token punctuation">,</span> <span class="token string">'ship'</span><span class="token punctuation">,</span> <span class="token string">'truck'</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
      
    <span class="token comment"># Rescale the weights to be between 0 and 255</span>
    wimg <span class="token operator">=</span> <span class="token number">255.0</span> <span class="token operator">*</span> <span class="token punctuation">(</span>w<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> w_min<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>w_max <span class="token operator">-</span> w_min<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>wimg<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'uint8'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>classes<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p><img src="/2022/10/24/cs231n-2/output.png"></p>
</blockquote>
<p><em><strong>*Inline question 2*</strong></em></p>
<p>Describe what your visualized SVM weights look like, and offer a brief explanation for why they look the way they do.</p>
<p>$\color{blue}{\textit Your Answer:}$ 部分图片跟所属类别相似，例如dog类很像一只带着蓝色项圈的泰迪坐在地上，car类很像一辆红色的小汽车行驶在水泥路上，deer类就像一只棕色的鹿穿行在绿色的丛林里。因为每个类别的weight都是从对应类别的图形中学习得来，所以得到的是对应类别的模板。</p>
<h3 id="比较与总结"><a href="#比较与总结" class="headerlink" title="比较与总结"></a>比较与总结</h3><ul>
<li><p>训练：在训练过程中，SVM损失函数当正确分类高于边界线一定阈值时就不再提升；softmax损失函数会不断push正确分类的概率越来越高</p>
</li>
<li><p>效果：在本例中，训练得到的SVM分类器在测试集上正确率为37.9%，softmax分类器正确率为38.1%，两者之间相差不大，但均比KNN分类器高了很多。</p>
</li>
</ul>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">Knowledge</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="http://knowledge-llz.github.io/2022/10/24/cs231n-2/">http://knowledge-llz.github.io/2022/10/24/cs231n-2/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">Knowledge</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">
                                    <span class="chip bg-color">机器学习</span>
                                </a>
                            
                                <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">
                                    <span class="chip bg-color">计算机视觉</span>
                                </a>
                            
                                <a href="/tags/%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E5%99%A8/">
                                    <span class="chip bg-color">线性分类器</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2022/10/30/information-retrieval/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/17.jpg" class="responsive-img" alt="信息检索学习笔记（一）">
                        
                        <span class="card-title">信息检索学习笔记（一）</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2022-10-30
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Information-Retrieval/" class="post-category">
                                    Information Retrieval
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2/">
                        <span class="chip bg-color">信息检索</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2022/10/16/cs231n-1/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/0.jpg" class="responsive-img" alt="Stanford-cs231N笔记（一）：KNN算法">
                        
                        <span class="card-title">Stanford-cs231N笔记（一）：KNN算法</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2022-10-16
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" class="post-category">
                                    人工智能
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">机器学习</span>
                    </a>
                    
                    <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">
                        <span class="chip bg-color">计算机视觉</span>
                    </a>
                    
                    <a href="/tags/KNN/">
                        <span class="chip bg-color">KNN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2022-2023</span>
            
            <a href="/about" target="_blank">Knowledge</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">64.6k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2022";
                        var startMonth = "3";
                        var startDate = "28";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/knowledge-llz" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:925538513@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=925538513" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 925538513" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
